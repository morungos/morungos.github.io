What is artificial intelligence?

The first and probably most frequent answer is that it is a *technology*, an application
of scientific methods -- especially machine learning -- for progress.

A second answer is that it is a *ideological*, even a *political* project,
designed to re-centre power structures. This position is eloquently summarised
by [Ali Alkhatib](https://ali-alkhatib.com/blog/defining-ai).

This is a strong statement, particularly when it makes claims about intent. 

Of course, this doesn't mean that strong proponents of artificial intelligence
(the likes of Elon Musk, Peter Thiel, Marc Andreesen, Sam Altman) don't have a
political intent to consolidate power. They clearly do. However, it is one thing
to claim that a technology was *intended* for a purpose, and another that it is
being *appropriated* for that purpose. 

A second issue I find somewhat problematic is the claim to AI's being "drenched
in blood from military funding". In the United States, I think this is likely
true -- but the US is not the whole history of artificial intelligence. In the
UK, the same field (initially under the name "machine intelligence") had a
different history. It remained close to cybernetics, and to some extent
neuroscience too, 

But, despite the fact that far the majority of UK funding in the field was not
military, I digress. Let's get back to the point. 

There are several reasons why I am skeptical.

1. Political or ideological use of technology tends to be opportunistic rather
   than strategic.

2. Tech company founders have a proven record of not being strategic.

Consider Google. It had no real business model -- apart from growth (same for
Amazon, by the way). To think that Google shaped AI is to give them too much
credit. The whole process of entrepreneurship is to tinker with your product
until you get traction, then experiment to find your business model. There is
system and method, but it is not strategic. 

Or, even more obviously, Musk's various undertakings -- PayPal, Space X, Tesla,
Hyperloops, Twitter. There's no strategy there, just opportunism. He just throws
shit, and sees what sticks. The idea that Musk is capable of playing 3D chess to
the point of actually infusing AI into products to intentionally shift autonomy
away from individuals, that's very much at odds with, for example, PayPal. 

Of course, Musk being Musk, the pipe dream of self-driving cars is a magnificent
grift if you want to get tech bros to part with tens of thousands of dollars for
a product that not only does not exist, but that Tesla does not yet know even
how to build. Again, it's opportunism.

I save Thiel for last, because he's the one that does seem genuinely strategic.
His agenda is chilling. 

However, even there, history doesn't match. Palantir even rejected artificial
intelligence early on, focusing on data, people, and "intelligence
augmentation". 

In other words, no large technology founders were embracing artificial
intelligence until around 2010 at the earliest, even in products (such as 
Palantir) that apparently did have political and ideological ambitions.

1. Pivotal early work was not under the control of US ideologies.

But let's see if we can sharpen the thesis up a little and let it stand. 

It is possible that artificial intelligence truly is just another technology,
and that all its impacts are the product of a hype cycle and marketing.
Possible, but highly unlikely. 

What I think makes artificial almost unique, and interesting, is that it is
capable of "mass individualization". Previously in the modern era, scale and
productivity were characterized by uniformity -- a process that is still
continuing in manufacturing.[^Production] However, manufacturing and service
sectors have very different dynamics. For that reason, applications of
artificial intelligence in manufacturing are often much less problematic.

[^Production]: There are glimpses of a parallel process of mass
    individualization in manufacturing too, for example, with the rise of 3D
    printing and CNC machine tools. 

## Services

One massive difference is that, in service industries, economics of scale
work differently. 

In manufacturing, let's say you make cars, it is cost effective to make 
every single car, and as far as possible every single part, as similar as
possible. Obviously people like to buy things that are a little bit personal,
so personalization does come into it, but it tends to be superficial. 

In services, that doesn't work. Patients don't all have the same diseases,
taxpayers don't have the same taxes or incomes.

So, the historical rise of services is almost a consequence of modernization
achieving greater productivity in manufacturing -- that is, until the rise of
technologies like artificial intelligence, which enable scale and automation in
services. Early technologies included vending machines and the humble ATM, but the
internet and others soon followed.

Now, we have added artificial intelligence, which is unique because it is the
first to cross application boundaries.

Point is, it is not the technology that is the problem. Applications of machine
learning are not, fundamentally, a mechanism to established centralised power
systems. However, in services, they provide an entirely new set of tools that
naturally do, by default, established centralised power systems. 

Let's look at example: risk prediction (I chose this, because of the United
Healthcare story). Algorithmic systems for doing this go back a long way --
credit scoring is perhaps the best known -- and, as such, they predate what we
today know as artificial intelligence. Like the UH story, credit scoring systems
function to individualize risk, to download it from a corporation to its service
clients. Artificial intelligence makes it a little bit more opaque and
unaccountable, but not all that much, to be fair. Old school credit scoring
itself can be fairly bad -- as can any system that aims to computationally
attach a risk to a person.

But what if we use the exact same algorithm differently, to, for example,
estimate the risks caused by a storm, or the risks of extinction for a species, 
or the risk of an appliance brand failing. These are all potentially beneficial,
because they don't individualize risk at all. 

In other words, it isn't the technology, its the application. 

## Attribution theory

Let's go back to the issue of blame. This is something of a cheat, as we're
treating artificial intelligence as an actor, but this is solely for a purpose
of allocating blame. We can, and will, play the same technique on Elon in a
moment.

1. Consensus: how do other people in the same situation behave with the same stimulus?

2. Distinctiveness: does the same person behave differently with different stimuli?

3. Consistency: does the same person behave similarly with the same stimulus in other situations?

The stereotypical example might be: "Jo laughed at the comedian". We might want
to understand what *caused* this to happen. If Jo laughs at everything
(distinctiveness), that's evidence in favour of Jo being the attributed as the
cause. If everyone laughed at the comedian at the same time (consensus) that's
evidence in favour of the comedian being the cause. And if Jo has seen the
comedian ten times and only laughed once (consistency) it's more likely one
lucky joke.

Now let's apply this framework. Let's start with Ali Alkhatib's framing:

> "AI is an ideological project to shift authority and autonomy away from
> individuals, towards centralized structures of power."

First, what if there are lots of other projects to shift authority and
autonomy away from individuals? Are there? In many cases, yes. The US alone
there is Citizens United, the overturning of Roe, ...

Next, does artificial intelligence act differently on other tasks. Again, yes.
The same technology, especially outside the service sector, has a much smaller
impact on authority and autonomy. Sure, it can still have employment
consequences, which may be dramatic, .... [ is power over robots centralizing? ]

Finally, does artificial intelligence have a different centralizing effect in 
different situations? Once again, yes. 

Now let's do Elon.

1. Does Elon always 