---
layout: post
title: 'Breaking the machines'
author: Stuart
background: '/img/posts/iphone-3635262_1920.jpg'
summary: >-
  A blog post ...  
image: '/img/posts/iphone-3635262_1920.jpg'
image_description: |-
  A modern smartphone, broken apart, after being hit by an old rusty 
  hammer with a wooden handle
---

### Prologue

For several reasons, it's been a while since my last post. One big part of that
has been because I've been slowly putting together a more substantial text on
the relationships between artificial intelligence and society. But, with life
being the way it is, it's taking (a lot) longer to finish, so now seemed like a good
time to set out the core argument of that longer piece. So, read on, but also
bear with me -- this is not a finished article, but a work in progress --
and *on* progress, I suppose.

# Breaking the machines 

Why has artificial intelligence enabled such awful things to happen? Why has this
straightforward technology caused so much distress, to so many people in different
contexts, in such a short time? What is it about this specific technology that
makes it able to do this? Because, underneath it all, the technology behind 
artificial intelligence is still relatively crude. 

And some of the things that artificial intelligence has enabled are unspeakably awful, from the 
[unfounded accusations of criminal acts based on facial recognition](https://www.nytimes.com/2023/08/06/business/facial-recognition-false-arrest.html) to 
[incorrectly failing students for plagiarism](https://www.washingtonpost.com/technology/2023/04/01/chatgpt-cheating-detection-turnitin/),
and
recipes including [glue, rocks](https://www.thestar.com/entertainment/glue-on-pizza-eating-rocks-is-ai-now-trying-to-kill-us-in-the-kitchen/article_6f330bc4-1dde-11ef-b9fa-47eac1daa1d0.html), 
and even
[chlorine gas](https://www.stuff.co.nz/business/132725271/paknsaves-ai-meal-planner-suggests-recipe-for-deadly-chlorine-gas).

The flippant answer might be: it's all capitalism. I don't buy that. Capitalism
is, by definition, all about the money — and what is happening here is not in
markets where there is a whole lot of money floating around. It's impacting art,
education, crime, pornography -- people in those fields are generally not the 
wealthy and powerful. Sure, it's the rich folks that are backing artificial 
intelligence, but at least so far, it's hard to see the big money flows you'd 
expect. 

So, instead, I want to explore a different interpretation — that what artificial
intelligence is doing, underneath all the tech bro nonsense and media hype, is
enabling a wholly new level of modernization to happen, in spheres which had
previously been more or less untouched. 

That is not to minimize the problem, because this might be even worse than
full-blown capitalism. We do see the impacts of the technology
disproportionately falling on the less wealthy and the less privileged, but not
only in the form of capital. So, let's dig in, and look at the argument about
what is unique about artificial intelligence and why it is an important but
singularly dangerous about it.

# The big picture

In rough outline, the argument I want to make is as follows:

1. AI is primarily a technology of reflexive modernization, not capitalism
2. Therefore, AI enables large-scale individualization
3. Therefore, AI enables creation at scale of new, manufactured risks
4. Therefore, AI enables organized irresponsibility, i.e., dumping risks onto
   society and the less privileged

## 1. Artificial intelligence is a technology of reflexive modernity

What artificial intelligence brought was a change in what could be automated. Up
to that point, it had generally been routine manual skilled work that had been
automated. But by the 1980s, industrialization had reached a point that the need
for skilled employees was becoming less, and entire economies began
to move away from manufacturing and towards services.

One of the key characteristics of reflexive modernity is that risks start to
become substantially more important. In Beck's memorable phrasing, where earlier
stages of modernity revolved around the trade of "goods", in reflexive
modernity, "bads" takes centre stage. Where "goods", like wealth, tend to flow
upwards, to the more wealthy and the more privileged, "bads" tend to flow
downwards, to the less wealthy and the less privileged.

Those "bads" can be everything from financial derivatives (the selling of risks
was a fundamental part of the 2008 sub-prime mortgage crisis and subsequent
global downturn) to the outsourcing of employment risks through the rise in the
gig economy, abuse of social media for political influence, and 

"But," i hear you say, "what evidence do you have? Surely this is just some 
social sciencey bollocks?"  

## 2. Artificial intelligence enables individualization

Individualization looks like freedom, from a distance, but it is not freedom up
close. Instead, each one of us is navigating the world alone in our own personal
maze of twisty little passages, all alike. Artificial intelligence is what makes
these mazes different for each one of us. 

A pivotal example of this was the Cambridge Analytica scandal -- mining psychometric 
data from Facebook to build models that were capable of targeting political 
advertising to individuals based on their predicted pressure points in their
personality profiles. The individualization of advertising. 

Of course, it's not the only technology of individualization -- others include
marketplaces, cryptocurrencies, digital rights management, surveillance
technologies, to name but a few. 

## 3. Artificial intelligence creates new, manufactured risks, at scale

Artificial intelligence itself is not particularly ‘risky’ as a technology —
there’s no evidence it creates any greater hazards than other technological
innovations — but it is a technology that processes and manages ‘risks’ in ways
that transform the social order. This deserves a different kind of analysis than
the technology usually gets, which has tended to focus on dramatic stories from
science fiction, rather than the mundane realities of real people’s everyday
lives and livelihoods.

## 4. Artificial intelligence enables organized irresponsibility

Organized irresponsibility is when people are able to act so they are
responsible but not accountable. Traditionally, responsibility worked in a
relatively simple way (Galantino):

- Experts analyze foreseeable risks and make recommendations, but are not
  accountable
- Decision-makers choose how to act based on experts’ recommendations, and are
  accountable
- Unforeseeable risks fall outside accountability

With artificial intelligence, not only are the experts obfuscated, but the
decision-makers themselves begin to vanish. For example, when Apple Pay was
treating men and women differently in credit approvals with otherwise identical
circumstances, ...

Or, when Amazon makes firing decisions based on algorithmic inferences, or
when educators are giving failing grades based on incorrect determinations of
plagiarism -- all of these are creating a space where there is a lack of 
accountability. Rights and justice are simply denied.

The EU policies on artficial intelligence make a good start on these problems, 
by identifying the high risk situations where the lack of accountability is
most problematic. But, ultimately, classifying certain decision areas as 
"high risk" will miss others, which can be equally damaging. The 

"No decisions without accountability" might be a better rule of thumb.


# But is it capitalism?

At first glance, it does look like wer might blame capitalism. Many of the
biggest advocates of artificial intelligence are the first round of tech bros
from the dotcom iteration, now turned into venture capitalists driving
technology investments. The likes of Peter Thiel, Elon Musk, Jeff Bezos, Marc
Andreesen, Paul Graham, Eric Schmidt, Sam Altman, and so on, although many
others are less well-known. For rhese rich and powerful people, this is a way to
become more rich and more powerful. For many, artificial intelligence offers a
way of automating a large swathe of industries out of existence entirely -- the
ultimate act of creative destruction. 

But if we look more closely, this isn't pure capitalism -- at least, not yet.
There isn't all that much product money in generative AI. Sure, there's massive
investment, government funding, and so on. But it all looks much more like 
it's driven more by fear of missing out on future markets, rather than more
mundane customer revenues. And -- significantly -- a lot of the discourse
suggests it's more like an ideology, a technological imperative to progress, 
if you like.

2. Neoliberalism

Another theory, closely related, is that the guilty party is neoliberalism. The 
distinction seem subtle, but it isn't: capitalism is, really, all about the
money; neoliberalism is an ideology. 

3. Acceleration



4. Modernization


In this sense, artificial intelligence isn’t even particularly transformative —
instead, it is part of a suite of transformations, along with the computer,
large-scale electronics, and the internet. Together, these have continued the
process of modernization into every fragment of the world we live in. Artificial
intelligence cannot be separated from these other technologies. 

That’s the central point: 

For instance, let’s consider AI generated images. While they are, by some,
defended as ‘remix’, ‘commentary’ or even a reaction to art, in fact, by
dramatically restructuring the economics, they allow factory-scale production of
work that resembles art, to a point where art itself ceases to be
viable. It doesn't even mock art, because mocking requires irony, and irony
requires knowing the difference between the real and the simulated -- and this is
precisely what is dissolving. There is no reaction or commentary left --
everything has gone into the great industrial generative sausage machine. 

Don't get me wrong, I like sausages now and again, but I couldn't live off them
every single day.

## Breaking the machines

How, as a society, can we deal with this? 

We can learn some lessons from history. During the Industrial Revolution, many
new movements sprang up to press for an an improved balance within the emerging
capitalist systems. These movements included the early co-operatives, trades
unions, and even utopian socialist communities. Some worked to fill the gaps in
the system, some pressed for change within it, and some walked away to create
their own alternatives.

A few went further: not all groups were this peaceful. One, which by today’s
standards would likely be called terrorists, were the Luddites, named after a
(probably apocryphal) figure,ne ‘Ned Ludd’. Their main strategy was ‘machine
breaking’, sabotaging the devices that the employers depended on to deliver
their improved productivity. As a protest, it was as much against the
devaluation of skill that these machines represented, as it was about the new
modern world itself. 

There are parallels today. Writers' unions are actively fighting the technology.
Image tools like Nightshade aim to poison the well of
generative AI, at least in art. It is almost impossible to do this with text, so
other writers are simply withdrawing their texts from public access, to take it
out of the reach of the generative sausage machines.





## Is artificial intelligence important?

Artificial intelligence plays a role similar to that mechanization in the early
Industrial Revolution. At that time, mechanization allowed human skills to be
captured and deployed at scale. This reduced the need for people with those
uniquely human skills, and enabled their previous employers to increase their
efficiency while reducing their costs. Commercially and economically, this makes
perfect sense.


## A Valley mystery



There's a lot wrong with the way the world works. Inequality is rife,
so is prejudice. Politics is breaking into partisan divisiveness. Wherever
we look, everything seems to be going to hell. The question is... who did it?

Labelling what AI does as capitalism, let alone automated, isn’t exactly the
phrasing I’d use, for several reasons.

1. It immediately creates a binary framing.
2. By virtue of that, it asserts that AI is incompatible with any form for
   socialism (e.g., my favourite economic democracy). This is not necessarily
   true. There are many ways AI could enable socialism. Obviously, the shape of
   the deployments would be entirely different, but that’s the point.

For these reasons, my preferred way to look at the modern era is not as a
neoliberal capitalist hellscape, but as liquid or reflexive modernization. 


## Clue the first: reflexive modernity 

An alternative way to think about recent social changes is: instead of a
"breakdown" in the process of modernization, such that 

Instead, since around 1990 or so, the world moved into a new phase of
modernization -- what Zygmunt Bauman called "liquid modernity" and Ulrich Beck,
Anthony Giddens, and Scott Lash variously called "reflexive modernity". This is
not an "end" of modernization, but a "closing the loop", if you like, where
modernization reached a point where it could transform the process of
modernization itself, allowing progress to start happening in wholly new 
and unexpected directions. 

## Clue the second: artificial intelligence

## Clue the third: risk machines

## Clue the fourth: regulation

The current focus of attention on avoiding damaging consequences for
artificial intelligence is on regulation. Regulation is, after all, what 
societies need to do to protect people from damaging consequences and 
perverse incentives. And it comes in all shapes and sizes from licensing
(as is common in medicine, for both treatments and practitioners), to
legal responsibiilities (as it common in the financial and business
sectors), to laws.

Take copyright, for example. Copyright evolved as a response to abusive
behaviours from printers, who would literally sell copies of texts,
without the authors consent or permission. Copyright created a new 


## Clue the fifth: a modern Panopticon

## Concluding thoughts

So let's look at the evidence. First of all Open AI mentions safety much 
more than responsibility, but they do mention responsibility a few times,
for example:

> ### Safety in practice
> 
> We develop risk mitigation tools, best practices for responsible use, 
> and monitor our platforms for misuse.
https://openai.com/safety-systems/

Note, though, that "best practices for responsible use" is pushing
responsibility onto their users, not accepting it themselves. This is
exactly what we'd expect from organized irresponsibility. 

> You must not use any Output relating to a person for any purpose that could have
> a legal or material impact on that person, such as making credit, educational,
> employment, housing, insurance, legal, medical, or other important decisions
> about them. 
https://openai.com/policies/terms-of-use/

In other words, it is users that remain legally liable for anything that 
comes out of the system. 

> Even if there is no negligence, however, public policy demands that
> responsibility be fixed wherever it will most effectively reduce the hazards
> to life and health inherent in defective products that reach the market.

It is obvious that this is not happening in the case of Open AI, or with
AI products more generally. In fact, by introducing an artificial intelligence
system, the precise location of responsibility is obscured -- and that's 
the point.