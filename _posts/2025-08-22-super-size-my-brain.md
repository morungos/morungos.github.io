---
title: Super size my brain: self-actualization and AI
---

When I hear the increasing stories of the effects of large language models --
which increasingly seem to be transforming people's mental capacities in
ways that are obviously harmful -- I wonder if there's a useful analogy with
[Morgan Spurlock's "Super Size Me"](https://www.imdb.com/title/tt0390521/)?

In effect, is there a kind of “cognitive diet” that can be good — or bad — for
us? Can we end up consuming information in a way that slowly poisons us,
destroying our ability to function independently. 

In effect, are our mental capacities malleable or not? 

If they are malleable -- what if they are capable of being damaged by certain
processes and stimuli?[^trauma]

[^trauma]: Let's leave trauma out of this, and focus more on more everyday
experiences.

## Maslow's hierarchy of needs

One way to think about this is through the framework of Abraham Maslow, and
especially his "hierarchy of needs", today usually depicted as a pyramid
(although Maslow never depicted it that way). At the bottom are the basic needs,
and only once those are being met are we able to explore higher ones. At the top
was "self-actualization", which is most relevant here[^Maslow].

[^Maslow]: This is the simple version of Maslow's model, which is more nuanced
    than commonly presented. Maslow himself mentioned that levels of need could
    be switched around from person to person and context to context. However, Maslow's
    point was that people who are fulfilled and happy tend to have a significant
    proportion of self-actualization in their mix. 

Maslow studied a fair number of "self-actualizers" (ranging from Einstein to
Harriet Tubman), to find out what they had in common, and what marked them apart
from the rest of us. All in all, he found about fifteen common behaviours,
summarised in the table below. 

It's worth noting here that I'm talking about Maslow's original
(semi-)qualitative work, not the abuses of his description that came later,
especially in the popularization of his framework within the business community.

| Maslow's self-actualization               | Naive generative AI                                                   |
| ----------------------------------------- | --------------------------------------------------------------------- | 
| Efficient perception of reality           | Increasing distortion of reality, recursive environment drift[^Ruane] |
| Acceptance of self, others, and nature    | Guilt, shame, anxiety                                  |
| Spontaneity, simplicity, naturalness      | Greater salience of social norms                                      |
| Goal centered, long-term mission in life  | Satisficing, local optimization                                       |
| Accepting solitude without discomfort     | Constant need for social interaction                                  |
| Autonomy and independence                 | Increasing dependency on the perceptions of others                    |
| Continued freshness of appreciation       | Digital amnesia[^Deckker]                                             |
| Mystic (flow) experiences, awe            | Diminishing cognitive control and attention regulation[^Deckker]      |
| Gemeinschaftsgegühl (community feeling)   | Loss of community boundaries and identities, individualization        |
| Profound interpersonal relations          | Wider but shallower social networks                                   |
| Democratic character; humility, justice   | Halo effects, judgements are shaped by overall perceptions            |
| Discrimination between good and evil      | Moral relativism, both-sidesing, the paradox of tolerance             |
| Philosophical, un-hostile sense of humour | Satire, "punch down" comedy                                           |
| Child-like creativity                     | Creativity shaped by other people's perceptions and expectations.     |
| Resistance to enculturation               | "Fast culture", rapidly-evolving, viral, imitative              .     |

Now, as a mostly careful cognitive scientist, I will be careful not pin my
argument only on Maslow's work, which was distinctly sloppy by today's
standards. Fortunately, I don't need to. One more respectable related concept is
*need for cognition*, a personality-linked behavioural disposition (Cacioppo &
Petty, 1982), which uses psychometrics to measure individual differences. 

Also, it is not clear that these effects are causal. It is very likely that
individual cognitive differences lead people to choose to interact with
generative Ai tools. THere's a selection bias in the mix. 

## Relations to business

It's intriguing that by far and away the biggest impact of Maslow's framework
was in the business literature, where it very quickly caught on -- and the
pyramid diagrams today associated with Maslow were generated and propagated
entirely within this community. 

However when you read, there's an ironic tension in the literature. It is
invariably aimed at managers -- and it is not a coincidence that the pyramid
resembles a corporate structure, so self-actualization becomes more the realm of
managers, and basic needs that of lower rank employees. 

And yet, to Maslow, it was all about personal growth: "the desire to become more
and more what one is, to become everything that one is capable of becoming"
(Maslow, 1943). 

Reading the business literature, much of it reads like senior managers yelling
at their more junior employees: "grow, damn you!". The "self" part of
"self-actualization" is entirely missing. 

## Self-actualization versus self-image actualization

In a rare moment of insight, Fritz Perls (Perls was often a bit of an asshole,
to be honest -- especially to his wife) revealed a piece of the framework that
Maslow had missed. As Perls put it: "Many people dedicate their lives to
actualize a concept of what they *should* be like, rather than to actualize
*themselves*" (Perls, 1969, p20, original emphasis).

This is crucial: Maslow's framework was all about people growing, becoming all
that they could be. But, all to easily, a need for esteem, other other needs,
provides a kind of saccharine substitute, a simulation of growth. 

One great example of this is [this
article](https://www.cbc.ca/documentaries/the-passionate-eye/does-being-manly-make-you-healthier-and-happier-the-top-5-reasons-the-answer-is-nope-1.7358633)
and the accompanying CBC documentary [*Harder Better Faster
Stronger*](https://gem.cbc.ca/harder-better-faster-stronger). Remember: Maslow's
point is essentially that happiness and fulfillment come with
self-actualization. This documentary shows the harms of actualizing self-image
(as a "real man") instead. As with the generative AI in the table above, all too
easily guilt, shame, and anxiety replace the acceptance of self and others in
true self-actualization.

## Artificial intelligence as a dark mirror

One of the few true experts in both artificial intelligence and in
psychoanalytic thinking is Sherry Turkle. Her classic, *The Second Self*,
explores the mirror as a metaphor for intelligent machines (for want of a better
term), in some depth. One passage is worth quoting in full:

> Ours has been called a culture of narcissism. The label is apt but can be
> misleading. It reads colloquially as selfishness and self-absorption. But
> these images do not capture the anxiety behind our search for mirrors. We are
> insecure in our understanding of ourselves, and this insecurity breeds a new
> preoccupation with the question of who we are. We search for ways to see
> ourselves. The computer is a new mirror, the first psychological machine.
> Beyond its nature as an analytical engine lies its second nature as an
> evocative object. (Turkle, 1984, p279).

Turkle's insight completes the puzzle. Maslow's needs are basic drives, and as
we see ourselves in the mirror of new artificial intelligence, we all too easily
see a false self-image -- ourselves as we wish to be seen: creative, autonomous,
rich, powerful, beautiful, loved. We want our super-sized brain -- and, more
importantly, we *need* everyone else to see it.

And ChatGPT, the evocative mirror of our new technological world, can persuade
us that this self-image is real. Whether or not this is by design, it happens:
psychological mirroring and boundary dissolution were two of the most
significant patterns identified by Ruane in her analysis of maladaptive human-AI
relationships,

Generative AI -- in its current dominant form as a tool -- is directly harmful
to self-actualization.

## Positive psychology

Maslow called his approach "positive psychology", predating and significantly
inspiring Seligman's and others work.

Vibe coding, for example, has a lot of positive psychology in it -- emphasis
on feeling rather than thinking, 

And like positive psychology, it brings new problems -- again, usually, where
the image overtakes the realization. Oddly, negativity is actually associated
with a better perception of reality.

## One alternative: slow AI

Of course, there are other ways the technology can work -- Slow AI is one example, 

> [There] is a playfulness to slow technology, an artistic aspect that encourages 
> time to reflect. We need to start building AI applications that focus less on 
> the goal, and more on our experiences living in the world we do.

The problem is, slow AI is harder to design and to build. it requires thought
and skill to help build an experience that goes beyond this illusion -- and,
oddly, the kinds of skills that great artists and great game designers often
excel at. I want the technology experiences of a Banksy, not a Musk.

## Another alternative: stories

Another approach is to step away from reflecting one person, and instead show
reflections of other -- real -- people. That was the basis of Roger Schank's 
"ASK Systems". One great example was the "Sounding Board" -- it had a chat-like
interface but instead of using generative text to tell you what to do, it 
presented short video clips of what other real people had done, maybe even in
slightly different situations. 

This changes the way we perceive the information: we have to work, cognitively,
to apply the information. And we get to see the value in other people's
expertise, so we can see the value our own more accurately. 

## Generative artificial intelligence:

So, will generative artificial intelligence make us into cognitive couch
potatoes? Will it exert a pressure that makes self-actualization harder? 
There hasn't been a whole lot of research on this, but I think there is a 
case to answer.

In a way, it all comes down to the basic question we asked at the start: are our
mental capacities malleable or not? 

If they aren't, then generative artificial intelligence is 

But if they are, if we need to rise towards self-actualization to be happy 


## References

Cacioppo, J. T., & Petty, R. E. (1982). The need for cognition. *Journal of
Personality and Social Psychology*, **42**(1), 116–131.
https://doi.org/10.1037/0022-3514.42.1.116

Maslow, A. H. (1943). A theory of human motivation. *Psychological Review*, **50**(4),
370–396. https://doi.org/10.1037/h0054346


## Notes


Recursive environment drift
* https://www.psychologytoday.com/us/blog/the-algorithmic-mind/202508/how-ai-chatbots-may-blur-reality
