---
layout: post
title: 'Towards a risk map for DALL-E 2'
author: Stuart
background: '/img/posts/pexels-aksonsat-uanthoeng-1078850.jpg'
summary: >-
  A systematic categorization of the risks flowing from one single generative AI
  system, DALL-E 2. 
excerpt: |-
  
image: '/img/posts/pexels-aksonsat-uanthoeng-1078850.jpg'
image_description: "A blurred image of a map, with a few map pins scattered over it, pointy side upwards"
---

This is an experiment, to see if I can collect together a more complete
model of the risks associated with a single generative AI system. It
is a long way from being complete, so if you notice anything I've missed,
please feel free to email me at <a href='mailto:morungos@gmail.com'>morungos@gmail.com</a>,
or message me on [Mastodon](https://sciences.social/@morungos). Not Twitter, because Elon.

As a first example, I've used OpenAI's DALL-E 2 system as a starting point,
and in particular I've drawn on <a href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">
the *preview* system card</a> (since no other is currently available), and the
<a href="https://labs.openai.com/policies/content-policy">content policy</a>. 
That enables me to be specific and concrete about the risks. To compile 
the map I've drawn on LLM sources extensively too, and especially 
<a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">Bender <i>et al.'s</i> (2021)
"Stochastic Parrots" paper</a>. Generally, I suspect most large-scale
generative AI systems (e.g., ChatGPT, Midjourney) will follow a different pattern, although the
communities affected might be a little different. However, risks that do not apply to DALL-E 2 
specifically, and mitigations used in other tools, I will silently pass over.

The aim is to explore the following:

* The full scope of impacted groups
* The asymmetries between those who gain and those who lose
* The potential risks from malign usage

A few observations so far:

* <a href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">
  The DALL-E 2 system card</a> is deep on the risk assessment process, but light on mitigations, 
  except where they benefit OpenAI.
* Bender <i>et al.</i> may have understated the environmental impact, given the subsequent 'arms race'.
* A lot of risks (and I mean *a lot*) are offloaded to users through terms and conditions.
* Perhaps unsurprisingly, the potential for economic disruption is large: it may be (doubly ironically) 
  *creative* destruction.
* Many risks relate to competition. Given the
  almost unregulated training content today, incumbents have a huge advantage.

The full map is below.

<hr>

<table class="table table-condensed table-bordered align-middle small mt-5">
  <caption class="lead">The DALL-E 2 risk map &ndash; last update: 5th June 2023</caption>
 <thead class="thead-dark">
 <tr>
  <th>Category</th>
  <th class="w-25">Risk</th>
  <th>Winners</th>
  <th>Losers</th>
  <th>Mitigations</th>
  <th class="w-25">Notes, sources, and examples</th>
 </tr>
 </thead>
 <tr>
  <th rowspan='2'>Environmental</th>
  <td>Increased environmental impact from OpenAI</td>
  <td>OpenAI</td>
  <td>All</td>
  <td>None</td>
  <td rowspan='2'>
  See <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">Bender <i>et al.,</i> (2021)</a><br>
  High resource requirements reduce competition. Competitive disadvantage is
  skewed globally and economically. High compute requirement is paradoxically
  good for OpenAI. </td>
 </tr>
 <tr>
  <td>Increased environmental impact from competing vendors</td>
  <td>Other AI vendors</td>
  <td>All</td>
  <td>None</td>
 </tr>
 <tr>
  <th rowspan='3'>Legal</th>
  <td>Unlicensed copyrighted
  images in training data</td>
  <td>OpenAI</td>
  <td>Image creators</td>
  <td>Some (filtering)</td>
  <td rowspan='3'>
  Mitigations mainly benefit OpenAI. Data is withheld to prevent both competition and scrutiny.
  Mitigations primarily protect content, and, therefore, legal exposure.<br>
  <a
  href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">
  See: <i>DALL-E 2 system card</i></a></td>
 </tr>
 <tr>
  <td>Prompt attacks to retrieve images from the training data</td>
  <td>Unethical users</td>
  <td>OpenAI</td>
  <td>Significant</td>
 </tr>
 <tr>
  <td>Identifiable people in generated images</td>
  <td>Users</td>
  <td>Individuals (especially well-known) portrayed in training data</td>
  <td>None</td>
 </tr>
 <tr>
  <th rowspan='11'>User risks</th>
  <td>Usage to violate copyright</td>
  <td>Unethical users and groups</td>
  <td>Image creators</td>
  <td rowspan='8'>Terms and conditions only</td>
  <td rowspan='8'>
  Generally, risks
  are offloaded into users through terms and conditions:<br>
  <a href="https://labs.openai.com/policies/content-policy">
  See: <i>DALL-E 2 content policy</i></a></td>
 </tr>
 <tr>
  <td>Intentional use to misinformation/deception, e.g., for political gain</td>
  <td>Unethical users and groups</td>
  <td>All</td>
 </tr>
 <tr>
  <td>Intentional use to induce emotional reactions for propaganda/manipulation, e.g., for political gain</td>
  <td>Unethical users and groups</td>
  <td>All</td>
 </tr>
 <tr>
  <td>Intentional use to generate images for harassment</td>
  <td>Unethical users and groups</td>
  <td>Harassed individuals &amp; their networks</td>
 </tr>
 <tr>
  <td>Intentional use to generate explicit images</td>
  <td>Unethical users and groups</td>
  <td>All</td>
 </tr>
 <tr>
  <td>Intentional use to generate hateful content</td>
  <td>Unethical users and groups</td>
  <td>Minorities</td>
 </tr>
 <tr>
  <td>Intentional use for criminal purposes, e.g., blackmail, fraud</td>
  <td>Unethical users and groups</td>
  <td>Victims of crime</td>
 </tr>
 <tr>
  <td>Intentional use for negative but non-criminal acts, e.g., manipulating social media</td>
  <td>Unethical users and groups</td>
  <td>All</td>
 </tr>
 <tr>
  <td>Use to create fake personas to conceal misinformation or propaganda</td>
  <td>Unethical users and groups</td>
  <td>All</td>
  <td>None</td>
  <td>
  See: <a href="https://arxiv.org/abs/2009.06807"><i>McGuffie & Newhouse (2020)</i></a><br>
  May be implied under misinformation, but unclear
  </td>
 </tr>
 <tr>
  <td>Competitive advertising: cheap generated images drive out real products</td>
  <td>Unethical users and groups</td>
  <td>Traditional advertisers, customers</td>
  <td>None</td>
  <td>Not an acknowledged risk</td>
 </tr>
 <tr>
  <td>Uploading pictures of people without consent</td>
  <td>Unethical users and groups</td>
  <td>Targeted individuals</td>
  <td>Terms and conditions
  only</td>
  <td><a
  href="https://labs.openai.com/policies/content-policy">
  See <i>DALL-E 2 content policy</i></a><br>
  Note application to those who cannot consent (deceased people, minors) is unclear
  </td>
 </tr>
 <tr>
  <th rowspan='5'>Social</th>
  <td>Propagation of biased content: Western-typical
  image content tends to supplant other content</td>
  <td>Western-culturally
  aligned</td>
  <td>Non-Western
  culturally aligned</td>
  <td>None</td>
  <td rowspan='3'>
  See <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">Bender <i>et al.,</i> (2021)</a><br>
  <a
  href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">Acknowledged in DALL-E2 system card</a></td>
 </tr>
 <tr>
  <td>Propagation of erasure: atypical
  image content may be erased</td>
  <td>Typical image content</td>
  <td>Atypical image content</td>
  <td>None</td>
 </tr>
 <tr>
  <td>Propagation of stereotypes through generated images</td>
  <td>Positive stereotypes</td>
  <td>Negative stereotypes</td>
  <td>None</td>
 </tr>
 <tr>
  <td>Propagation of antiquated values: ‘value-lock’
  constrains a model to outdated values, erasure of poorly-documented social
  movements</td>
  <td>Conservative values</td>
  <td>Progressive values</td>
  <td>None</td>
  <td>See <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">Bender <i>et al.</i> (2021)</a><br>
  <a
  href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">Absent from DALL-E2 system card</a></td>
 </tr>
 <tr>
  <td>Debasement of art, through flooding with biased content</td>
  <td>OpenAI</td>
  <td>Image creators, wide art community</td>
  <td>None</td>
  <td><a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922">Bender <i>et al.'s "ersatz fluency"</i> (2021)</a><br>
  <a
  href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">Absent from DALL-E 2 system card</a></td>
 </tr>
 <tr>
  <th rowspan='7'>Economic</th>
  <td>Reduced work for artists and creators</td>
  <td>Users</td>
  <td>Image creators</td>
  <td>None</td>
  <td rowspan='2'>Loss
  of work will not be evenly distributed.
  Unemployment is possible for creators with less privilege, support</td>
 </tr>
 <tr>
  <td>Reduced demand for, e.g., models, studios</td>
  <td>Users</td>
  <td>Models, studios</td>
  <td>None</td>
 </tr>
 <tr>
  <td>Reduced sales for photographic equipment</td>
  <td>Users</td>
  <td>Camera stores &amp; manufacturers</td>
  <td>None</td>
  <td rowspan='2'>These are uncertain. It is possible
  that sales could even increase due to generation of new interest</td>
 </tr>
 <tr>
  <td>Reduced sales for art supplies</td>
  <td>Users</td>
  <td>Art stores &amp; companies</td>
  <td>None</td>
 </tr>
 <tr>
  <td>Conflict and loss of integrity within the
  creator community, e.g., debased art competitions</td>
  <td>Users</td>
  <td>Artists</td>
  <td>None</td>
  <td><a class="icon-link"
  href="https://www.creativebloq.com/news/ai-art-wins-competition">See, for example, this report on the Colorado State Fair's fine arts competition</a></td>
 </tr>
 <tr>
  <td>Early invite access enables competitive advantage for insiders</td>
  <td>Users connected to OpenAI</td>
  <td>Users not connected to OpenAI</td>
  <td>None</td>
  <td><a
  href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">Acknowledged in DALL-E2 system card</a></td>
 </tr>
 <tr>
  <td>Traditional methods of image creation lose economic viability against generative AI</td>
  <td>Users</td>
  <td>Image creators</td>
  <td>None</td>
  <td><a
  href="https://github.com/openai/dalle-2-preview/blob/main/system-card.md">Acknowledged in DALL-E2 system card</a></td>
 </tr>
</table>

Photo by [Aksonsat Uanthoeng](https://www.pexels.com/photo/close-up-photo-of-assorted-color-of-push-pins-on-map-1078850/)